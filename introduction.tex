\chapter{Introduction}

\cite{fitts:1967:hp}

Performing highly dynamic motions with agility and grace has been
one of the greatest challenges in sports, computer animation, and robotic.
A wide variety of athletic, such as acrobatic or free running, demonstrate the
efficient and artistic movements which involve the abrupt changes of momentum
and contacts.
Furthermore, these motor skills are transferred to virtual characters 
in animation and game to express the intention of designers
and react to user interactions.
Robotics, another application of dynamic controllers, also started 
to tackle the agile movements and demonstrated
running, jumping, and landing motions with real hardwares.
Despite the recent progress, 
learning dynamic motor skills still remains a very difficult
problem because it needs to execute the task with great agility, 
ensure the safety, and demonstrate the self-expression.

In fact, developing dynamic controllers for virtual characters and
real robots can be considered as related problems
which can benefit each other.
Since the control problems in two domains have shared properties,
such as non-linearity, high-dimension, and disconstiuity,
an algorithm developed in one domain can be transferred 
to the other domain.
However, control of real robots is more constrained
due to the sensor uncertainty and hardware limitations which 
usually requires more robustness than control of virtual
characters.
Therefore, developing an algorithm in virtual environment to prove its
full capability and transferring it to real hardwares would be
a nice research direction, which is adopted in this proposal.

In computer animation and robotics community, various categories
of algorithms have been applied to control virtual and real characters.
For generating a sequence of dynamic motion, two approaches has been
frequently applied to control problems: tracking the reference motion, or 
solving the space-time optimization problem under the physics constraints.
Both methods demonstrated that a variety of motions can be achieved 
by solving the optimization problem which considers the entire sequence
of motions.
However, the optimization over the entire motion usually requires
a long optimization time and further falls short of abilities
for adapting the motion to new environments.
On the other hand, abstract model based controllers can be interactively
adapted to a wide range of situations by capturing the essential features
of the dynamic motion.
This approach shows the robust control over various motions,
such as walking, balancing, and falling, but hard to consider the
very detailed features such as the exact boundary of characters 
or a sequence of contacts.
A sampling-based optimization for the parameterized controllers has proven
effective for optimizing the motion within a realistic simulation environment,
but it also takes a long time to be optimizzed, especially when the objective
function is parameterized or concatenated for long term goals.



In this proposal, we introduce a set of techniques to expedite
the learning process of dynamic controllers for various dynamic motor 
skills. We first introduce a natural and safe landing controller for
the characters and robots, which is essential for highly dynamic motions.
After that, we propose an interactive syste to design dynamic controllers
for humanoids. The rest of sections are organized as follows:


\section{Organizations}

\begin{itemize}
\item 
  \textbf{Optimization of Falling and Landing motions}
  In this proposal, we tackle the problem of controlling safe falling 
  and landing motion for virtual characters and robots, which is a fundamental
  motor skill because highly dynamic motions involve the abrupt changes
  of contacts and can cause huge damages on the body parts.
  While absorbing the shock at the impact, a successful landing controller 
  also should be able to maintain readiness for the next action by managing
  the momentum properly.
  For the virtual character, we introduce a fast and robust optimization 
  algorithm for controlling falling and landing motions of virtual
  characters from a wide rage of heights and initial speeds.
  while reducing joint stress.
  Further, we develop a safe falling algorithm for a robot by planning a sequence of
  multiple contacts, which endures larger external perturbatations comparing to
  the existing methods.

\item 
  \textbf{Human-guided iterative framework for training dynamic motions}
  Also, we introduce an iterative training system for dynamic motor skills
  inspired by human coaching techniques, which uses human-in-the-loop
  (HITL) optimization for interactive training.
  In this system, the user only needs to provide a primitive initial controller
  and high-level, human-readable instructions as if coaching a human trainee.
  The virtual character interprets the provided instructions,
  accumulate the knowledge from the human coach,
  and iteratively improves its motor skills by optimizing control parameters.
  We propose a new hierarchical representation of controllers, 
  the ``motor tree'' for interpreting the instructions and accumulating
  the knowledge on motions.
  In addition, we develop a new sampling-based optimization method,
  Covariance Matrix Adaptation with Classification (CMA-C), 
  which efficiently solves the constrained problem by estimating
  the infeasible region from bad samples.
  The system is further extended by considering the hardware limitations 
  and uncertainties to support training dynamic motions for robots.
  With the proposed system, we demonstrate the design process of
  comlex dynamic controllers including jumps, vaults, rolls, and flips.

%% \item 
%%   \textbf{Future Plan}
%%   In this section, we briefly introduce our estimated plan until the defense.


\end{itemize}

%% \subsection{Interactive Optimization of Falling and Landing for character animation}
%% In this section, ..

%% \subsection{Optimization of Multi-contact Falling sequence for robots}
%% In this section, ..


%% Learning a dynamic motor skill, such as a precision jump in Parkour or
%% a flip in gymanstics usually requires an iterative training process
%% with interactive coaching and repetitive practices.
%% Even though details of the learning process remain unknown,
%% Pitts and Posner \cite{fitts:1967:hp} hypothesize the three stages
%% of the skill acquisition process: the cognitive stage, 
%% the associative stage, and the autonomous stage.
%% The cognitive stage is when the trainee gathers information about the new
%% skill or receives the feedback on the existing skills from the coach
%% via instructions.
%% In the associative stage, the learner translates the declarative knowledge
%% to functional movements after an unspecified amount of practice and few mistakes.
%% In the autonomous stage, the skill has become almost automatic or habitual 
%% so that it can be executed with minimal amount of efforts.
%% A key of this hypothesis is an iterative process between cognitive learning
%% and physical training.
%% With this intuition, we propose a human-in-the-loop optimization 
%% framework to design dynamic controllers for virtual characters,
%% which consists of the ``coaching'' stage for receiving user instructions 
%% and the ``practicing'' stage for optimizing control parameters.

%% In fact, the iterative training system can greatly simplify the design
%% process of dynamic controllers by exploiting the same mechanism as human.
%% Moreover, since our system incrementally develops the controller by
%% accumulating human knowledge, the existing controllers can be easily
%% adapted, extended, or concatenated for new situations.
%% However, several new research questions arise when we formalize the
%% elusive principles of human learning into mathematical models for
%% designing physics-based controllers, such as mapping the human instruction
%% to low-level control variables or representing the accumulated knowledge
%% on motor skills.
%% To resolve the issues, we introduce a new hierarchical representation 
%% of motor skills, the ``motor tree'', to simulate the phenomenon of
%% skill abstraction and accumulation. 
%% To increase the responsiveness, the motor tree is optimized at interactive
%% rates by exploiting the previous failure history or idle time of the system.

%% In this proposal, we introduce a framework and related algorithm to simulate the learning process of human.
